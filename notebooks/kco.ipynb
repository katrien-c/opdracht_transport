{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6195dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5966a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATIE_REQUESTS = os.path.join(\"../data/requests\")\n",
    "RUWE_DATA_CSV = os.path.join('../data/ruw/all_ruwe_data.csv')\n",
    "GEKREGEN_EXCEL_FILE = os.path.join('../data/ModifiedQueryRows.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(file_name) -> tuple:\n",
    "    try:\n",
    "        # rsplit verwijdert alleen de laatste .json extensie (voor mocht het bestand meerdere .json bevatten alhoewel dit onwaarschijnlijk lijkt)\n",
    "        parts = file_name.rsplit('.json', 1)[0].split('-')\n",
    "        if len(parts) >= 5:\n",
    "            route_id = parts[0]\n",
    "            date = parts[1]\n",
    "            time = parts[2]\n",
    "            number_of_tasks = parts[3]\n",
    "            number_of_tasks_in_input_plan = parts[4]\n",
    "            return route_id, date, time, number_of_tasks, number_of_tasks_in_input_plan\n",
    "        else:\n",
    "            print(f\"Skipping file {file_name}: incorrect format\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing file name {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if csv bestand bestaat\n",
    "def check_csv_bestand(bestandspadennaam) -> bool:\n",
    "    if os.path.exists(bestandspadennaam):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# lees csv bestand in als dataframe\n",
    "def lees_dataframe_uit_csv(bestandspadennaam) -> pd.DataFrame:\n",
    "    df = pd.read_csv(bestandspadennaam)  \n",
    "    return df\n",
    "\n",
    "# maak csv bestand aan vanuit dataframe\n",
    "def schrijf_dataframe_naar_csv(df: pd.DataFrame, bestandspadennaam) -> None:\n",
    "    # Maak de directory aan als deze niet bestaat\n",
    "    os.makedirs(os.path.dirname(bestandspadennaam), exist_ok=True)\n",
    "    # Schrijf het dataframe naar CSV\n",
    "    df.to_csv(bestandspadennaam, index=False)\n",
    "    return None\n",
    "\n",
    "# de verschillende json-bestanden van de requests inladen en samenvoegen tot 1 grote dataframe \n",
    "# geeft een dataframe terug als resultaat\n",
    "def lees_json_bestanden_en_maak_dataframe(locatie_requests) -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    for folder_name in os.listdir(locatie_requests):\n",
    "        folder_path = os.path.join(locatie_requests, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith('.json'):\n",
    "                    parsed_data = parse_filename(file_name)\n",
    "                    if parsed_data == None:\n",
    "                        break\n",
    "                    else:\n",
    "                        route_id, date, time, number_of_tasks, number_of_tasks_in_input_plan = parsed_data\n",
    "                        # print(route_id, date, time, number_of_tasks, number_of_tasks_in_input_plan)\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "                        with open(file_path, 'r') as f:\n",
    "                            data = json.load(f)\n",
    "                            # Voeg route_id toe aan elke record in data\n",
    "                            data['route_id'] = route_id\n",
    "                            data['date'] = date\n",
    "                            data['time'] = time\n",
    "                            data['number_of_tasks'] = number_of_tasks\n",
    "                            data['number_of_tasks_in_input_plan'] = number_of_tasks_in_input_plan\n",
    "                            temp_df = pd.DataFrame([data])\n",
    "                            # voeg tijdelijke dataframe toe aan de hoofddataframe\n",
    "                            df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f70fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (check_csv_bestand(RUWE_DATA_CSV) == False):\n",
    "    # maak het bestand een eerste keer\n",
    "\n",
    "    ingelezen_dataframe = lees_json_bestanden_en_maak_dataframe(LOCATIE_REQUESTS)\n",
    "    # dit is dan dezelfde dataframe als in de gegeven excel file maar met tasks en fixedTasks eraan toegevoegd en zonder TriggerType\n",
    "    # date en time zijn nog steeds strings, kan later nog omgezet worden naar datetime indien nodig\n",
    "    # timecalculation, \n",
    "    display(ingelezen_dataframe.head())\n",
    "\n",
    "    schrijf_dataframe_naar_csv(ingelezen_dataframe, RUWE_DATA_CSV)\n",
    "\n",
    "    display(ingelezen_dataframe.tail())\n",
    "    print(f\"Lengte van de dataframe: {len(ingelezen_dataframe)}\")\n",
    "    # excel inlezen om de lengte te checken\n",
    "    df_excel = pd.read_excel(GEKREGEN_EXCEL_FILE)\n",
    "    print(f\"Aantal rijen in ingelezen excel dataframe: {len(df_excel)}\")\n",
    "    if (len(ingelezen_dataframe) != len(df_excel)):\n",
    "        print(\"Waarschuwing: Aantal rijen in ingelezen dataframe komt niet overeen met aantal rijen in excel dataframe!\")\n",
    "\n",
    "else:\n",
    "    # lees het bestand en voeg toe aan dataframe om verder mee te werken\n",
    "    ingelezen_dataframe = lees_dataframe_uit_csv(RUWE_DATA_CSV)\n",
    "    display(ingelezen_dataframe.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582a836",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# dataframe met tasks maken\n",
    "taken_df = ingelezen_dataframe[['id', 'tasks']].copy()\n",
    "# type van tasks is een string dus moeten we dit eerst omzetten\n",
    "def safe_eval(x):\n",
    "    \"\"\"Veilige evaluatie van lijststrings, werkt ook als pd.isna vastloopt.\"\"\"\n",
    "    # Eerst basischecks\n",
    "    if x is None or x == '':\n",
    "        return []\n",
    "\n",
    "    # Dan pas pd.isna (werkt voor echte NaN waarden)\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "    except Exception:\n",
    "        pass  # Als pd.isna niet kan, gewoon doorgaan\n",
    "\n",
    "    # Als het al een lijst is\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "\n",
    "    # Als het een string is, probeer te evalueren\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            import ast\n",
    "            return ast.literal_eval(x)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    # Alles wat overblijft → lege lijst\n",
    "    return []\n",
    "\n",
    "# def safe_eval_no_ast(x):\n",
    "#     \"\"\"Veilige conversie van string naar lijst zonder ast.literal_eval.\"\"\"\n",
    "#     if not x or pd.isna(x):\n",
    "#         return []\n",
    "\n",
    "#     # Alleen lijsten herkennen: iets dat begint met [ en eindigt met ]\n",
    "#     x = x.strip()\n",
    "#     if x.startswith('[') and x.endswith(']'):\n",
    "#         # Items splitsen op komma, strip aanhalingstekens en spaties\n",
    "#         items = re.findall(r\"(?:'([^']*)'|\\\"([^\\\"]*)\\\"|([^,\\[\\]]+))\", x)\n",
    "#         result = []\n",
    "#         for t in items:\n",
    "#             # t is een tuple van drie, één element is gevuld\n",
    "#             value = next(filter(None, t))\n",
    "#             value = value.strip()\n",
    "#             # Probeer int of float te maken, anders als string\n",
    "#             if value.isdigit():\n",
    "#                 result.append(int(value))\n",
    "#             else:\n",
    "#                 try:\n",
    "#                     result.append(float(value))\n",
    "#                 except ValueError:\n",
    "#                     result.append(value)\n",
    "#         return result\n",
    "\n",
    "#     # Als het geen lijststring is, return lege lijst\n",
    "#     return []\n",
    "\n",
    "\n",
    "taken_df['tasks'] = taken_df['tasks'].apply(safe_eval)\n",
    "taken_df = taken_df.explode('tasks')\n",
    "tasks_normalized = pd.json_normalize(taken_df['tasks'])\n",
    "\n",
    "tasks_normalized = tasks_normalized.rename(columns={\n",
    "    'id': 'task_id',\n",
    "    'address.latitude': 'latitude',\n",
    "    'address.longitude': 'longitude',\n",
    "    'timeWindow.from': 'from',\n",
    "    'timeWindow.till': 'till'\n",
    "})\n",
    "tasks_normalized['id'] = taken_df['id'].values\n",
    "tasks_normalized = tasks_normalized.reset_index(drop=True)\n",
    "\n",
    "display(tasks_normalized.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df28c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe met fixedTasks maken\n",
    "fixed_taken_df = ingelezen_dataframe[['id', 'fixedTasks']].copy()\n",
    "# filter om alleen rijen te tonen waar fixedTasks niet leeg is\n",
    "fixed_taken_df = fixed_taken_df[fixed_taken_df['fixedTasks'].astype(str) != '[]']\n",
    "\n",
    "fixed_taken_df['fixedTasks'] = fixed_taken_df['fixedTasks'].apply(safe_eval)\n",
    "# fixedTasks omzetten van string naar object\n",
    "fixed_taken_df = fixed_taken_df.explode('fixedTasks')\n",
    "\n",
    "# alleen rijen behouden waar fixedTasks niet leeg is\n",
    "fixed_taken_df = fixed_taken_df[fixed_taken_df['fixedTasks'].notna()]\n",
    "fixed_taken_df = fixed_taken_df[fixed_taken_df['fixedTasks'] != {}]\n",
    "\n",
    "# normaliseren van fixedTasks\n",
    "fixed_tasks_normalized = pd.json_normalize(fixed_taken_df['fixedTasks'])\n",
    "\n",
    "# kolommen hernoemen voor consistentie\n",
    "if not fixed_tasks_normalized.empty:\n",
    "    # voeg id kolom toe\n",
    "    fixed_tasks_normalized['id'] = fixed_taken_df['id'].values\n",
    "    fixed_tasks_normalized = fixed_tasks_normalized.reset_index(drop=True)\n",
    "\n",
    "display(fixed_tasks_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unieke locatie IDs toevoegen aan tasks_normalized\n",
    "# Punten binnen 6 meter van elkaar krijgen dezelfde location_id\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Bereken de afstand tussen twee punten op aarde in meters\n",
    "    \"\"\"\n",
    "    # Aardstraal in meters\n",
    "    R = 6371000\n",
    "    \n",
    "    # Converteer naar radialen\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    \n",
    "    # Haversine formule\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Bereid data voor clustering voor\n",
    "coords = tasks_normalized[['latitude', 'longitude']].copy()\n",
    "\n",
    "# Verwijder rijen met missende coördinaten\n",
    "coords_clean = coords.dropna()\n",
    "\n",
    "# Converteer naar radialen voor DBSCAN met haversine metric\n",
    "coords_rad = np.radians(coords_clean[['latitude', 'longitude']].values)\n",
    "\n",
    "# DBSCAN clustering\n",
    "# eps in radialen: 6 meter / 6371000 meter (aardstraal) ≈ 0.000000941\n",
    "eps_rad = 6 / 6371000  \n",
    "dbscan = DBSCAN(eps=eps_rad, min_samples=1, metric='haversine')\n",
    "clusters = dbscan.fit_predict(coords_rad)\n",
    "\n",
    "# Voeg cluster labels toe aan de originele dataframe\n",
    "tasks_normalized['location_id'] = np.nan\n",
    "tasks_normalized.loc[coords_clean.index, 'location_id'] = clusters\n",
    "\n",
    "# Converteer naar integer waar mogelijk\n",
    "tasks_normalized['location_id'] = tasks_normalized['location_id'].astype('Int64')\n",
    "\n",
    "# Toon resultaat\n",
    "print(f\"Aantal unieke locaties: {tasks_normalized['location_id'].nunique()}\")\n",
    "print(f\"Aantal taken: {len(tasks_normalized)}\")\n",
    "display(tasks_normalized[['task_id', 'latitude', 'longitude', 'location_id']].head(20))\n",
    "\n",
    "# Toon een voorbeeld van taken die dezelfde locatie delen\n",
    "duplicated_locations = tasks_normalized[tasks_normalized.duplicated(subset=['location_id'], keep=False)]\n",
    "if len(duplicated_locations) > 0:\n",
    "    print(f\"\\nVoorbeeld van {len(duplicated_locations)} taken die locaties delen:\")\n",
    "    display(duplicated_locations.sort_values('location_id').head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg location_id toe aan fixed_tasks_normalized\n",
    "# Match op basis van task_id (van fixed_tasks) en id (route id)\n",
    "\n",
    "if not fixed_tasks_normalized.empty:\n",
    "    # Check welke kolom in fixed_tasks_normalized de task id bevat\n",
    "    # Dit zou 'taskId' of een vergelijkbare kolom moeten zijn\n",
    "    print(\"Kolommen in fixed_tasks_normalized:\")\n",
    "    print(fixed_tasks_normalized.columns.tolist())\n",
    "    print(\"\\nKolommen in tasks_normalized:\")\n",
    "    print(tasks_normalized.columns.tolist())\n",
    "    \n",
    "    # Bepaal de juiste kolom naam voor task_id in fixed_tasks_normalized\n",
    "    # Dit kan 'taskId', 'task_id', of een andere variant zijn\n",
    "    task_id_col = None\n",
    "    for col in fixed_tasks_normalized.columns:\n",
    "        if 'task' in col.lower() and 'id' in col.lower():\n",
    "            task_id_col = col\n",
    "            break\n",
    "    \n",
    "    if task_id_col:\n",
    "        # Merge om location_id toe te voegen\n",
    "        # Match op zowel de task_id als de route id\n",
    "        fixed_tasks_normalized = fixed_tasks_normalized.merge(\n",
    "            tasks_normalized[['task_id', 'id', 'location_id']],\n",
    "            left_on=[task_id_col, 'id'],\n",
    "            right_on=['task_id', 'id'],\n",
    "            how='left',\n",
    "            suffixes=('', '_from_tasks')\n",
    "        )\n",
    "        \n",
    "        # Verwijder de extra task_id kolom als die is aangemaakt\n",
    "        if 'task_id' in fixed_tasks_normalized.columns and task_id_col != 'task_id':\n",
    "            fixed_tasks_normalized = fixed_tasks_normalized.drop(columns=['task_id'])\n",
    "        \n",
    "        print(f\"\\nlocation_id toegevoegd aan fixed_tasks_normalized\")\n",
    "        print(f\"Aantal fixed tasks met location_id: {fixed_tasks_normalized['location_id'].notna().sum()}\")\n",
    "        print(f\"Aantal fixed tasks zonder location_id: {fixed_tasks_normalized['location_id'].isna().sum()}\")\n",
    "        \n",
    "        display(fixed_tasks_normalized.head(10))\n",
    "    else:\n",
    "        print(\"Kan geen task_id kolom vinden in fixed_tasks_normalized\")\n",
    "        display(fixed_tasks_normalized.head())\n",
    "else:\n",
    "    print(\"fixed_tasks_normalized is leeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ingelezen_dataframe.head())\n",
    "display(tasks_normalized.head())\n",
    "display(fixed_tasks_normalized.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
